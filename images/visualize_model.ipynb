{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=360, out_features=1000, bias=True)\n",
      "  (lif1): Leaky()\n",
      "  (fc2): Linear(in_features=1000, out_features=5, bias=True)\n",
      "  (lif2): Leaky()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from model import Net\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_inputs = 360\n",
    "num_hidden = 1000\n",
    "num_outputs = 5\n",
    "num_steps = 1\n",
    "beta = 0.95\n",
    "\n",
    "\n",
    "LIF_Model = Net(num_hidden, num_inputs, num_outputs, num_steps, beta).to(device)\n",
    "print(LIF_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnx\n",
      "  Obtaining dependency information for onnx from https://files.pythonhosted.org/packages/ff/24/0e522fdcadf0e15fc304145a5b6e5d7246d7f2c507fd9bfe6e1fafb2aa95/onnx-1.14.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading onnx-1.14.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages (from onnx) (1.24.3)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages (from onnx) (4.24.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages (from onnx) (4.5.0)\n",
      "Downloading onnx-1.14.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: onnx\n",
      "Successfully installed onnx-1.14.1\n"
     ]
    }
   ],
   "source": [
    "! pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%onnx::Gemm_0 : Float(1, 360, strides=[360, 1], requires_grad=0, device=cpu),\n",
      "      %fc1.weight : Float(1000, 360, strides=[360, 1], requires_grad=1, device=cpu),\n",
      "      %fc1.bias : Float(1000, strides=[1], requires_grad=1, device=cpu),\n",
      "      %lif1.threshold : Float(requires_grad=0, device=cpu),\n",
      "      %lif1.beta : Float(requires_grad=0, device=cpu),\n",
      "      %fc2.weight : Float(5, 1000, strides=[1000, 1], requires_grad=1, device=cpu),\n",
      "      %fc2.bias : Float(5, strides=[1], requires_grad=1, device=cpu),\n",
      "      %onnx::Mul_63 : Float(1, 1000, strides=[1000, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Mul_70 : Float(1, 5, strides=[5, 1], requires_grad=0, device=cpu)):\n",
      "  %lif2.beta : Float(requires_grad=0, device=cpu) = onnx::Identity(%lif1.beta)\n",
      "  %lif2.graded_spikes_factor : Float(requires_grad=0, device=cpu) = onnx::Identity(%lif1.threshold)\n",
      "  %lif2.threshold : Float(requires_grad=0, device=cpu) = onnx::Identity(%lif1.threshold)\n",
      "  %lif1.graded_spikes_factor : Float(requires_grad=0, device=cpu) = onnx::Identity(%lif1.threshold)\n",
      "  %/fc1/Gemm_output_0 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc1/Gemm\"](%onnx::Gemm_0, %fc1.weight, %fc1.bias), scope: model.Net::/torch.nn.modules.linear.Linear::fc1 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/lif1/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/lif1/Constant\"](), scope: model.Net::/snntorch._neurons.leaky.Leaky::lif1 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/snntorch/_neurons/leaky.py:214:0\n",
      "  %/lif1/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/lif1/Constant_1\"](), scope: model.Net::/snntorch._neurons.leaky.Leaky::lif1 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/snntorch/_neurons/leaky.py:214:0\n",
      "  %/lif1/Clip_output_0 : Float(requires_grad=0, device=cpu) = onnx::Clip[onnx_name=\"/lif1/Clip\"](%lif1.beta, %/lif1/Constant_output_0, %/lif1/Constant_1_output_0), scope: model.Net::/snntorch._neurons.leaky.Leaky::lif1 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/snntorch/_neurons/leaky.py:214:0\n",
      "  %/lif1/Mul_output_0 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/lif1/Mul\"](%/lif1/Clip_output_0, %onnx::Mul_63), scope: model.Net::/snntorch._neurons.leaky.Leaky::lif1 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/snntorch/_neurons/leaky.py:214:0\n",
      "  %/lif1/Add_output_0 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/lif1/Add\"](%/lif1/Mul_output_0, %/fc1/Gemm_output_0), scope: model.Net::/snntorch._neurons.leaky.Leaky::lif1 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/snntorch/_neurons/leaky.py:214:0\n",
      "  %/lif1/Sub_output_0 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Sub[onnx_name=\"/lif1/Sub\"](%/lif1/Add_output_0, %lif1.threshold), scope: model.Net::/snntorch._neurons.leaky.Leaky::lif1 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/snntorch/_neurons/neurons.py:81:0\n",
      "  %/lif1/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/lif1/Constant_2\"](), scope: model.Net::/snntorch._neurons.leaky.Leaky::lif1 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/snntorch/_neurons/neurons.py:271:0\n",
      "  %/lif1/Greater_output_0 : Bool(1, 1000, strides=[1000, 1], requires_grad=0, device=cpu) = onnx::Greater[onnx_name=\"/lif1/Greater\"](%/lif1/Sub_output_0, %/lif1/Constant_2_output_0), scope: model.Net::/snntorch._neurons.leaky.Leaky::lif1 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/snntorch/_neurons/neurons.py:271:0\n",
      "  %/lif1/Cast_output_0 : Float(1, 1000, strides=[1000, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/lif1/Cast\"](%/lif1/Greater_output_0), scope: model.Net::/snntorch._neurons.leaky.Leaky::lif1 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/snntorch/_neurons/neurons.py:271:0\n",
      "  %/lif1/Mul_1_output_0 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/lif1/Mul_1\"](%/lif1/Cast_output_0, %lif1.graded_spikes_factor), scope: model.Net::/snntorch._neurons.leaky.Leaky::lif1 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/snntorch/_neurons/neurons.py:84:0\n",
      "  %/fc2/Gemm_output_0 : Float(1, 5, strides=[5, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc2/Gemm\"](%/lif1/Mul_1_output_0, %fc2.weight, %fc2.bias), scope: model.Net::/torch.nn.modules.linear.Linear::fc2 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/lif2/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/lif2/Constant\"](), scope: model.Net::/snntorch._neurons.leaky.Leaky::lif2 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/snntorch/_neurons/leaky.py:214:0\n",
      "  %/lif2/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/lif2/Constant_1\"](), scope: model.Net::/snntorch._neurons.leaky.Leaky::lif2 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/snntorch/_neurons/leaky.py:214:0\n",
      "  %/lif2/Clip_output_0 : Float(requires_grad=0, device=cpu) = onnx::Clip[onnx_name=\"/lif2/Clip\"](%lif2.beta, %/lif2/Constant_output_0, %/lif2/Constant_1_output_0), scope: model.Net::/snntorch._neurons.leaky.Leaky::lif2 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/snntorch/_neurons/leaky.py:214:0\n",
      "  %/lif2/Mul_output_0 : Float(1, 5, strides=[5, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/lif2/Mul\"](%/lif2/Clip_output_0, %onnx::Mul_70), scope: model.Net::/snntorch._neurons.leaky.Leaky::lif2 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/snntorch/_neurons/leaky.py:214:0\n",
      "  %/lif2/Add_output_0 : Float(1, 5, strides=[5, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/lif2/Add\"](%/lif2/Mul_output_0, %/fc2/Gemm_output_0), scope: model.Net::/snntorch._neurons.leaky.Leaky::lif2 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/snntorch/_neurons/leaky.py:214:0\n",
      "  %/lif2/Sub_output_0 : Float(1, 5, strides=[5, 1], requires_grad=1, device=cpu) = onnx::Sub[onnx_name=\"/lif2/Sub\"](%/lif2/Add_output_0, %lif2.threshold), scope: model.Net::/snntorch._neurons.leaky.Leaky::lif2 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/snntorch/_neurons/neurons.py:81:0\n",
      "  %/lif2/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/lif2/Constant_2\"](), scope: model.Net::/snntorch._neurons.leaky.Leaky::lif2 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/snntorch/_neurons/neurons.py:271:0\n",
      "  %/lif2/Greater_output_0 : Bool(1, 5, strides=[5, 1], requires_grad=0, device=cpu) = onnx::Greater[onnx_name=\"/lif2/Greater\"](%/lif2/Sub_output_0, %/lif2/Constant_2_output_0), scope: model.Net::/snntorch._neurons.leaky.Leaky::lif2 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/snntorch/_neurons/neurons.py:271:0\n",
      "  %/lif2/Cast_output_0 : Float(1, 5, strides=[5, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/lif2/Cast\"](%/lif2/Greater_output_0), scope: model.Net::/snntorch._neurons.leaky.Leaky::lif2 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/snntorch/_neurons/neurons.py:271:0\n",
      "  %/lif2/Mul_1_output_0 : Float(1, 5, strides=[5, 1], requires_grad=1, device=cpu) = onnx::Mul[onnx_name=\"/lif2/Mul_1\"](%/lif2/Cast_output_0, %lif2.graded_spikes_factor), scope: model.Net::/snntorch._neurons.leaky.Leaky::lif2 # /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages/snntorch/_neurons/neurons.py:84:0\n",
      "  %/Constant_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant\"](), scope: model.Net:: # /home/ubuntu/Desktop/Projects/SNN/ecg_snn/model.py:46:0\n",
      "  %/Unsqueeze_output_0 : Float(1, 1, 5, strides=[5, 5, 1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze\"](%/lif2/Mul_1_output_0, %/Constant_output_0), scope: model.Net:: # /home/ubuntu/Desktop/Projects/SNN/ecg_snn/model.py:46:0\n",
      "  %55 : Float(1, 1, 5, strides=[5, 5, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=0, onnx_name=\"/Concat\"](%/Unsqueeze_output_0), scope: model.Net:: # /home/ubuntu/Desktop/Projects/SNN/ecg_snn/model.py:46:0\n",
      "  %/Constant_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_1\"](), scope: model.Net:: # /home/ubuntu/Desktop/Projects/SNN/ecg_snn/model.py:46:0\n",
      "  %/Unsqueeze_1_output_0 : Float(1, 1, 5, strides=[5, 5, 1], device=cpu) = onnx::Unsqueeze[onnx_name=\"/Unsqueeze_1\"](%/lif2/Add_output_0, %/Constant_1_output_0), scope: model.Net:: # /home/ubuntu/Desktop/Projects/SNN/ecg_snn/model.py:46:0\n",
      "  %58 : Float(1, 1, 5, strides=[5, 5, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=0, onnx_name=\"/Concat_1\"](%/Unsqueeze_1_output_0), scope: model.Net:: # /home/ubuntu/Desktop/Projects/SNN/ecg_snn/model.py:46:0\n",
      "  return (%55, %58)\n",
      "\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(LIF_Model, torch.randn(1, 360).to(device), \"images/LIF_Model.onnx\", verbose=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.onnx' has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/Desktop/Projects/SNN/ecg_snn/visualize_model.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ubuntu/Desktop/Projects/SNN/ecg_snn/visualize_model.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49monnx\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39m\u001b[39mimages/LIF_Model.onnx\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ubuntu/Desktop/Projects/SNN/ecg_snn/visualize_model.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# load('images/LIF_Model.onnx')\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ubuntu/Desktop/Projects/SNN/ecg_snn/visualize_model.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m dot \u001b[39m=\u001b[39m make_dot(model(torch\u001b[39m.\u001b[39mrandn(\u001b[39m1\u001b[39m, \u001b[39m360\u001b[39m)), params\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(model\u001b[39m.\u001b[39mnamed_parameters()))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.onnx' has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "model = torch.onnx.load('images/LIF_Model.onnx')\n",
    "# load('images/LIF_Model.onnx')\n",
    "dot = make_dot(model(torch.randn(1, 360)), params=dict(model.named_parameters()))\n",
    "dot.render('images/LIF_Model', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Obtaining dependency information for onnxruntime from https://files.pythonhosted.org/packages/d6/ee/82f181e561980bc59d53bbf14a32629a27c5c4290cfd193898f0d1933a6d/onnxruntime-1.16.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading onnxruntime-1.16.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m646.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flatbuffers in /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages (from onnxruntime) (23.5.26)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages (from onnxruntime) (1.24.3)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/.local/lib/python3.9/site-packages (from onnxruntime) (23.1)\n",
      "Requirement already satisfied: protobuf in /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages (from onnxruntime) (4.24.3)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages (from onnxruntime) (1.12)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m512.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /home/ubuntu/anaconda3/envs/work/lib/python3.9/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Downloading onnxruntime-1.16.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.16.1\n"
     ]
    }
   ],
   "source": [
    "! pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'InferenceSession' object has no attribute 'get_output_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/Desktop/Projects/SNN/ecg_snn/visualize_model.ipynb Cell 7\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ubuntu/Desktop/Projects/SNN/ecg_snn/visualize_model.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m sess \u001b[39m=\u001b[39m onnxruntime\u001b[39m.\u001b[39mInferenceSession(\u001b[39m\"\u001b[39m\u001b[39m/home/ubuntu/Desktop/Projects/SNN/ecg_snn/images/LIF_Model.onnx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ubuntu/Desktop/Projects/SNN/ecg_snn/visualize_model.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Get the names of the outputs of the model.\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ubuntu/Desktop/Projects/SNN/ecg_snn/visualize_model.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m output_names \u001b[39m=\u001b[39m sess\u001b[39m.\u001b[39;49mget_output_names()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ubuntu/Desktop/Projects/SNN/ecg_snn/visualize_model.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# For each output, create an image with the output data.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ubuntu/Desktop/Projects/SNN/ecg_snn/visualize_model.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m output_name \u001b[39min\u001b[39;00m output_names:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'InferenceSession' object has no attribute 'get_output_names'"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "\n",
    "# Load the ONNX model into a `onnxruntime` session.\n",
    "sess = onnxruntime.InferenceSession(\"/home/ubuntu/Desktop/Projects/SNN/ecg_snn/images/LIF_Model.onnx\")\n",
    "\n",
    "# Get the names of the outputs of the model.\n",
    "output_names = sess.get_output_names()\n",
    "\n",
    "# For each output, create an image with the output data.\n",
    "for output_name in output_names:\n",
    "    output = sess.get_output(output_name)\n",
    "    image = Image.fromarray(output)\n",
    "    image.save(output_name + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchview import gra"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
